{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudcard\n",
    "- **why is only the second column of predict_proba being used to find the best critical probability?**\n",
    "    - You can use either column but be careful of how you convert the critical probability to a predicted class\n",
    "    - If you use the first column, that's class 0 predicted probability. If it is larger than 50%, you need to predict class 0.\n",
    "    - If you use the second column, that's class 1 predicted probability. If it is larger than 50%, you need to predcit class 1.\n",
    "- **For decision trees and random forest, will we need to do the steps that we did during the quiz? Or is that what python will do for us?**\n",
    "    - slearn optimizes the decision tree for you and it also aggregates the votes of trees if you use a random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Supervised ML algorithms\n",
    "By the end of this week, you will be able to\n",
    "- Summarize how decision trees, random forests, and support vector machines work\n",
    "- Describe how the predictions of these techniques behave in classification and regression\n",
    "- Describe which hyper-parameters should be tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A decision tree in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "np.random.seed(10)\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "X = np.random.rand(n_samples)\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_new = np.linspace(0, 1, 1000)\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=1,max_depth=1)\n",
    "reg.fit(X[:, np.newaxis],y)\n",
    "y_new = reg.predict(X_new[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestRegressor in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestRegressor(ForestRegressor)\n",
      " |  RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest regressor.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of classifying\n",
      " |  decision trees on various sub-samples of the dataset and uses averaging\n",
      " |  to improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  For a comparison between tree-based ensemble models see the example\n",
      " |  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"},             default=\"squared_error\"\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"squared_error\" for the mean squared error, which is equal to\n",
      " |      variance reduction as feature selection criterion and minimizes the L2\n",
      " |      loss using the mean of each terminal node, \"friedman_mse\", which uses\n",
      " |      mean squared error with Friedman's improvement score for potential\n",
      " |      splits, \"absolute_error\" for the mean absolute error, which minimizes\n",
      " |      the L1 loss using the median of each terminal node, and \"poisson\" which\n",
      " |      uses reduction in Poisson deviance to find splits.\n",
      " |      Training using \"absolute_error\" is significantly slower\n",
      " |      than when using \"squared_error\".\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |         Poisson criterion.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=1.0\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None or 1.0, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. note::\n",
      " |          The default of 1.0 is equivalent to bagged trees and more\n",
      " |          randomness can be achieved by setting smaller values, e.g. 0.3.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to 1.0.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool or callable, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      By default, :func:`~sklearn.metrics.r2_score` is used.\n",
      " |      Provide a callable with signature `metric(y_true, y_pred)` to use a\n",
      " |      custom metric. Only available if `bootstrap=True`.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.DecisionTreeRegressor`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : DecisionTreeRegressor\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeRegressor\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_prediction_ : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |      Prediction computed with out-of-bag estimate on the training set.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      " |  sklearn.ensemble.ExtraTreesRegressor : Ensemble of extremely randomized\n",
      " |      tree regressors.\n",
      " |  sklearn.ensemble.HistGradientBoostingRegressor : A Histogram-based Gradient\n",
      " |      Boosting Regression Tree, very fast for big datasets (n_samples >=\n",
      " |      10_000).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  The default value ``max_features=1.0`` uses ``n_features``\n",
      " |  rather than ``n_features / 3``. The latter was originally suggested in\n",
      " |  [1], whereas the former was more recently justified empirically in [2].\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestRegressor\n",
      " |  >>> from sklearn.datasets import make_regression\n",
      " |  >>> X, y = make_regression(n_features=4, n_informative=2,\n",
      " |  ...                        random_state=0, shuffle=False)\n",
      " |  >>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      " |  >>> regr.fit(X, y)\n",
      " |  RandomForestRegressor(...)\n",
      " |  >>> print(regr.predict([[0, 0, 0, 0]]))\n",
      " |  [-8.32987858]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestRegressor\n",
      " |      ForestRegressor\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._forest.RandomForestRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestRegressor\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._forest.RandomForestRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestRegressor\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestRegressor:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict regression target for X.\n",
      " |      \n",
      " |      The predicted regression target of an input sample is computed as the\n",
      " |      mean predicted regression targets of the trees in the forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6fcec27ac04c0fa54a43f3e694ddb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='n_estimators', options=(1, 3, 10, 30), value=1), SelectionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################################################\n",
    "# HUGE thanks to Drew Solomon and Yifei Song (DSI alumni) \n",
    "# for preparing the visualizations in this lecture!\n",
    "#############################################################\n",
    "# check out helper_functions.ipynb for more details\n",
    "%run ./helper_functions.ipynb\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators': [1, 3, 10, 30],\n",
    "    'max_depth': [1, 2, 3, 10, 30]\n",
    "}\n",
    "\n",
    "vis(X, y, RandomForestRegressor, hyperparameters, X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to avoid overfitting with random forests?\n",
    "- tune some (or all) of following hyperparameters:\n",
    "   - max_depth\n",
    "   - max_features\n",
    "- With sklearn random forests, **do not tune n_estimators**!\n",
    "   - the larger this value is, the better the forest will be\n",
    "   - set n_estimators to maybe 100 while tuning hyperparameters\n",
    "   - increase it if necessary once the best hyperparameters are found\n",
    "- Some people don't like the steps (non-smooth) function given by random forest regression\n",
    "- Random forest is easy to interpret only when the hypter-params are small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|<font color='red'>so so</font> |<font color='red'>constant</font>|<font color='red'>yes</font>|<font color='red'>max_features,  max_depth</font>| <font color='red'>no</font>|<font color='red'>so so</font>|\n",
    "| random forest classification \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|\n",
    "| SVM rbf regression               \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|\n",
    "| SVM rbf classification           \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A random forest in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, n_estimators=1, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=3, n_estimators=1, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, n_estimators=1, random_state=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# create the data\n",
    "X,y = make_moons(noise=0.2, random_state=1,n_samples=200)\n",
    "# set the hyperparameters\n",
    "clf = RandomForestClassifier(n_estimators=1,max_depth=3,random_state=0)\n",
    "# fit the model\n",
    "clf.fit(X,y)\n",
    "# predict new data\n",
    "#y_new = clf.predict(X_new)\n",
    "# predict probabilities\n",
    "#y_new = clf.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  For a comparison between tree-based ensemble models see the example\n",
      " |  :ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      " |      Note: This parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool or callable, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      By default, :func:`~sklearn.metrics.accuracy_score` is used.\n",
      " |      Provide a callable with signature `metric(y_true, y_pred)` to use a\n",
      " |      custom metric. Only available if `bootstrap=True`.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : DecisionTreeClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      " |  sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
      " |      tree classifiers.\n",
      " |  sklearn.ensemble.HistGradientBoostingClassifier : A Histogram-based Gradient\n",
      " |      Boosting Classification Tree, very fast for big datasets (n_samples >=\n",
      " |      10_000).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(...)\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._forest.RandomForestClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestClassifier\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._forest.RandomForestClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._forest.RandomForestClassifier\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8275a1090d44609120e3c46d1a8178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='n_estimators', options=(1, 3, 10, 30), value=1), SelectionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7b78c4c7f54ac08fc898ec943d6875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorbar': {'title': {'text': 'predicted probability'}},\n",
       "              'colorsca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize RandomForestClassifier\n",
    "ML_algo = RandomForestClassifier(random_state=42) \n",
    "\n",
    "# set RF parameter grid\n",
    "hyperparameters = {\n",
    "    'n_estimators': [1, 3, 10, 30],\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "plot_clf_contour(hyperparameters, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|so so|constant|yes|max_features,  max_depth|no|so so|\n",
    "| random forest classification \t|<font color='red'>so so</font> |<font color='red'>step-like, difficult to tell</font>|<font color='red'>yes</font>|<font color='red'>max_features,  max_depth</font>| <font color='red'>no</font>|<font color='red'>so so</font>|\n",
    "| SVM rbf regression               \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|\n",
    "| SVM rbf classification           \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1\n",
    "- All trees are weighted equally in random forest\n",
    "- It is possible to create a tree with a maximum depth larger than 1 which splits on the same feature on each level/node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Support Vector Machine\n",
    "- very versatile technique, it comes in lots of flavors/types, read more about it [here](https://scikit-learn.org/stable/modules/svm.html)\n",
    "- SVM classifier motivation\n",
    "   - points in n dimensional space with class 0 and 1\n",
    "   - we want to find the (n-1) dimensional hyperplane that best separates the points\n",
    "   - this hyperplane is our (linear) decision boundary\n",
    "- we cover SVMs with radial basis functions (rbf)\n",
    "   - we apply a kernel function (a non-linear transformation) to the data points\n",
    "   - the kernel function basically \"smears\" the  points\n",
    "   - gaussian rbf kernel: $\\exp(-\\gamma (|x - x'|)^2)$ where $\\gamma > 0$\n",
    "   - Small gamma in regression: wide gaussion --> too small, a line\n",
    "   - Large gamma: peaks in the fitting curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "np.random.seed(10)\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "X = np.random.rand(n_samples)\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_new = np.linspace(-0.5, 1.5, 2000)\n",
    "\n",
    "reg = SVR(gamma = 1, C = 1)\n",
    "reg.fit(X[:, np.newaxis],y)\n",
    "y_new = reg.predict(X_new[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVR in module sklearn.svm._classes:\n",
      "\n",
      "class SVR(sklearn.base.RegressorMixin, sklearn.svm._base.BaseLibSVM)\n",
      " |  SVR(*, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |  \n",
      " |  Epsilon-Support Vector Regression.\n",
      " |  \n",
      " |  The free parameters in the model are C and epsilon.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time complexity\n",
      " |  is more than quadratic with the number of samples which makes it hard\n",
      " |  to scale to datasets with more than a couple of 10000 samples. For large\n",
      " |  datasets consider using :class:`~sklearn.svm.LinearSVR` or\n",
      " |  :class:`~sklearn.linear_model.SGDRegressor` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer or\n",
      " |  other :ref:`kernel_approximation`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
      " |       Specifies the kernel type to be used in the algorithm.\n",
      " |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |       used to precompute the kernel matrix.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Must be non-negative. Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features\n",
      " |      - if float, must be non-negative.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive.\n",
      " |      The penalty is a squared l2 penalty.\n",
      " |  \n",
      " |  epsilon : float, default=0.1\n",
      " |       Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
      " |       within which no penalty is associated in the training loss function\n",
      " |       with points predicted within a distance epsilon from the actual\n",
      " |       value. Must be non-negative.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `class_weight_` was deprecated in version 1.2 and will be removed in 1.4.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (1, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (1, n_SV)\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run by the optimization routine to fit the model.\n",
      " |  \n",
      " |      .. versionadded:: 1.1\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (1,), dtype=int32\n",
      " |      Number of support vectors.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV,)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  NuSVR : Support Vector Machine for regression implemented using libsvm\n",
      " |      using a parameter to control the number of support vectors.\n",
      " |  \n",
      " |  LinearSVR : Scalable Linear Support Vector Machine for regression\n",
      " |      implemented using liblinear.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n",
      " |      Machines and Comparisons to Regularized Likelihood Methods\"\n",
      " |      <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import SVR\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> rng = np.random.RandomState(0)\n",
      " |  >>> y = rng.randn(n_samples)\n",
      " |  >>> X = rng.randn(n_samples, n_features)\n",
      " |  >>> regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
      " |  >>> regr.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svr', SVR(epsilon=0.2))])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVR\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.svm._classes.SVR, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVR\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.svm._classes.SVR, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVR\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  class_weight_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  unused_param = 'random_state'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination of the prediction.\n",
      " |      \n",
      " |      The coefficient of determination :math:`R^2` is defined as\n",
      " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always predicts\n",
      " |      the expected value of `y`, disregarding the input features, would get\n",
      " |      a :math:`R^2` score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a precomputed\n",
      " |          kernel matrix or a list of generic objects instead with shape\n",
      " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      " |          is the number of samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      " |      This influences the ``score`` method of all the multioutput\n",
      " |      regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform regression on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd65fd8f5d843e69f786f1f565a250a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='gamma', options=(0.001, 0.1, 10.0, 1000.0, 100000.0), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hyperparameters = {\n",
    "    'gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5],\n",
    "    'C': [1e-1, 1e0, 1e1]\n",
    "}\n",
    "\n",
    "vis(X, y, SVR, hyperparameters, X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|so so |constant|yes|max_features,  max_depth| no|so so|\n",
    "| random forest classification \t|so so |step-like, difficult to tell|yes|max_features,  max_depth| no|so so|\n",
    "| SVM rbf regression               \t|<font color='red'>no</font>|<font color='red'>non-linear extrapolation</font>|<font color='red'>yes</font>|<font color='red'>C, gamma</font>|<font color='red'>yes</font>|<font color='red'>so so</font>|\n",
    "| SVM rbf classification           \t|              tbd             \t|           tbd          \t|     tbd     \t|        tbd       \t| tbd | tbd|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "\n",
    "Let's measure how long it takes to fit a linear regression, random forest regression, and SVR as a function of `n_samples` using our toy regression dataset. \n",
    "\n",
    "Check [this](https://stackoverflow.com/questions/7370801/how-do-i-measure-elapsed-time-in-python) stackoverflow post to figure out how to measure the execution time of a couple of lines of code. \n",
    "\n",
    "Set n_estimators to 10 and max_depth to 3 in the random forest. \n",
    "\n",
    "Set the gamma and C parameters to 1 in SVR. \n",
    "\n",
    "Fit models with n_samples = 1000, 2000, 3000, 4000, 5000. Measure how long it takes to fit each model.\n",
    "\n",
    "Plot the run time as a function of n_samples for the three models. You might need to adjust the y axis range to check some of the statements.\n",
    "\n",
    "Which of these statements are true?\n",
    "\n",
    "- The random forest run-time scales linearly with n_samples.\n",
    "- The linear regression model is the fastest to fit. \n",
    "- The SVR run-time scales worse than linear. (I.e., if we double n_sample, the fit time more than doubles.)\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "- The random forest run-time scales linearly with n_samples. \n",
    "- The linear regression model is the fastest to fit. \n",
    "- The SVR run-time scales worse than linear. (I.e., if we double n_sample, the fit time more than doubles.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "n_samples_list = [1000, 2000, 3000, 4000, 5000]\n",
    "linear_time = [[] for i in range(5)]\n",
    "rf_time =  [[] for i in range(5)]\n",
    "svr_time =  [[] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(n_samples_list)):\n",
    "    n_samples = n_samples_list[n]\n",
    "    X = np.random.rand(n_samples)\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    X_new = np.linspace(0, 1, 1000)\n",
    "    \n",
    "    for i in range(10):\n",
    "        start_time = time.time()\n",
    "        rf_reg = RandomForestRegressor(n_estimators=10,max_depth=3)\n",
    "        rf_reg.fit(X[:, np.newaxis],y)\n",
    "        y_new = rf_reg.predict(X_new[:, np.newaxis])\n",
    "        rf_time[n].append(time.time()-start_time)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        svr = SVR(gamma = 1, C = 1)\n",
    "        svr.fit(X[:, np.newaxis],y)\n",
    "        y_new = svr.predict(X_new[:, np.newaxis])\n",
    "        svr_time[n].append(time.time()-start_time)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        linear_reg = LinearRegression()\n",
    "        linear_reg.fit(X[:, np.newaxis],y)\n",
    "        y_new = linear_reg.predict(X_new[:, np.newaxis])\n",
    "        linear_time[n].append(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_time_mean = np.mean(np.array(linear_time), axis=1)\n",
    "svr_time_mean = np.mean(np.array(svr_time), axis=1)\n",
    "rf_time_mean = np.mean(np.array(rf_time), axis=1)\n",
    "\n",
    "linear_time_std = np.std(np.array(linear_time), axis=1)\n",
    "svr_time_std = np.std(np.array(svr_time), axis=1)\n",
    "rf_time_std = np.std(np.array(rf_time), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00045278, 0.00144525, 0.00038326, 0.0015871 , 0.00170453])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(n_samples_list, linear_time_mean, label='linear reg mean')\n",
    "plt.plot(n_samples_list, svr_time_mean, label='svr mean')\n",
    "#plt.plot(n_samples_list, rf_time_mean, label='rf reg mean')\n",
    "\n",
    "plt.xlabel(\"n_samples\")\n",
    "plt.ylabel(\"time\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_samples_list, linear_time_std, label='linear reg std')\n",
    "plt.plot(n_samples_list, svr_time_std, label='svr std')\n",
    "plt.plot(n_samples_list, rf_time_std, label='rf reg std')\n",
    "\n",
    "plt.xlabel(\"n_samples\")\n",
    "plt.ylabel(\"time\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n_samples = np.linspace(1000,5000,5,dtype=int)\n",
    "\n",
    "timer_lin = []\n",
    "timer_RF = []\n",
    "timer_SVR = []\n",
    "\n",
    "for n_sample in n_samples:\n",
    "    X = np.random.rand(n_sample)\n",
    "    y = true_fun(X) + np.random.randn(n_sample) * 0.1\n",
    "    \n",
    "    # add your code below\n",
    "\n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        reg = LinearRegression()\n",
    "        start_time = time.time()\n",
    "        reg.fit(X[:, np.newaxis],y)\n",
    "        end_time = time.time()    \n",
    "        times.append(end_time-start_time)\n",
    "    timer_lin.append(np.mean(times))\n",
    "\n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        reg = SVR(gamma = 1, C = 1)\n",
    "        start_time = time.time()\n",
    "        reg.fit(X[:, np.newaxis],y)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time-start_time)\n",
    "    timer_SVR.append(np.mean(times))\n",
    "    \n",
    "    times = []\n",
    "    for i in range(10):\n",
    "        reg = RandomForestRegressor(n_estimators=10,max_depth=3)\n",
    "        start_time = time.time()\n",
    "        reg.fit(X[:, np.newaxis],y)\n",
    "        end_time = time.time()  \n",
    "        times.append(end_time-start_time)\n",
    "    timer_RF.append(np.mean(times))\n",
    "\n",
    "# prepare the plot below:\n",
    "plt.plot(n_samples,timer_lin,'o',label='lin reg')\n",
    "plt.plot(n_samples,timer_RF,'o',label='RF')\n",
    "plt.plot(n_samples,timer_SVR,'o',label='SVR')\n",
    "plt.xlabel('n_samples')\n",
    "plt.ylabel('runtime')\n",
    "plt.ylim([0,0.1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=1, probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=1, probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=1, probability=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# create the data\n",
    "X,y = make_moons(noise=0.2, random_state=1,n_samples=200)\n",
    "# set the hyperparameters\n",
    "clf = SVC(gamma = 1, C = 1, probability=True)\n",
    "# fit the model\n",
    "clf.fit(X,y)\n",
    "# predict new data\n",
    "#y_new = clf.predict(X_new)\n",
    "# predict probabilities\n",
    "#y_new = clf.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer or\n",
      " |  other :ref:`kernel_approximation`.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Must be non-negative. Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features\n",
      " |      - if float, must be non-negative.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, note that\n",
      " |      internally, one-vs-one ('ovo') is always used as a multi-class strategy\n",
      " |      to train models; an ovr matrix is only constructed from the ovo matrix.\n",
      " |      The parameter is ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes * (n_classes - 1) // 2,)\n",
      " |      Number of iterations run by the optimization routine to fit the model.\n",
      " |      The shape of this attribute depends on the number of models optimized\n",
      " |      which in turn depends on the number of classes.\n",
      " |  \n",
      " |      .. versionadded:: 1.1\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic Outputs for Support Vector\n",
      " |      Machines and Comparisons to Regularized Likelihood Methods\"\n",
      " |      <https://citeseerx.ist.psu.edu/doc_view/pid/42e5ed832d4310ce4378c44d05570439df28a393>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.svm._classes.SVC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVC\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.svm._classes.SVC, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.svm._classes.SVC\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluate the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  probA_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  probB_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  unused_param = 'nu'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b305c7474064460e8ec84572558922ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectionSlider(description='gamma', options=(0.001, 0.1, 10.0, 1000.0, 100000.0), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a3d9ac55b1451ead739e36f1b30955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'colorbar': {'title': {'text': 'predicted probability'}},\n",
       "              'colorsca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize RandomForestClassifier\n",
    "ML_algo = SVC(probability=True)\n",
    "\n",
    "# SVC parameter grid\n",
    "hyperparameters = {\n",
    "    'gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5],\n",
    "    'C': [1e-1, 1e0, 1e1]\n",
    "}\n",
    "\n",
    "plot_clf_contour(hyperparameters, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| ML algo | suitable for large datasets? | behaviour wrt outliers | non-linear? | params to tune | smooth predictions | easy to interpret? |\n",
    "| - | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| linear regression            \t|              yes             \t|linear extrapolation|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| logistic regression          \t|              yes             \t|scales with distance from the decision boundary|      no     \t| l1 and/or l2 reg \t| yes | yes|\n",
    "| random forest regression     \t|so so |constant|yes|max_features,  max_depth| no|so so|\n",
    "| random forest classification \t|so so |step-like, difficult to tell|yes|max_features,  max_depth| no|so so|\n",
    "| SVM rbf regression               \t|no|non-linear extrapolation|yes|C, gamma|yes|so so|\n",
    "| SVM rbf classification           \t|<font color='red'>no</font>|<font color='red'>50-50</font>|<font color='red'>yes</font>|<font color='red'>C, gamma</font>|<font color='red'>yes</font>|<font color='red'>so so </font>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz 3\n",
    "Bias variance trade off\n",
    "\n",
    "Which gamma value gives the best trade off between high bias and high variance? Work through the steps to answer the question.\n",
    "\n",
    "- Use random_state = 42 where-ever necessary.\n",
    "- Split X, y into X_train, X_val, y_train, y_val such that 70% of the points are in train.\n",
    "- Fit SVC models with C = 1, and gamma = 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3 on the training set.\n",
    "- Measure the validation accuracy for each gamma.\n",
    "- Which gamma value gives the highest validation accuracy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mud card"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
